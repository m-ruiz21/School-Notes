
Mr. Graves poses the question:

<center><b>
Are artificial agents in any way members of religious community?
</b></center>

Cons:
- AI has no drive, no desire for converting one's life towards God's will.
- There is no desire for personal improvement, harmony with each other or nature

Pros:
- interpreting religious texts, adding insights that a religious community wouldn't have otherwise. 

How do we decide if the pros is enough to be a member of the community? 
	- By defining what it means to be a member of the community.

His definition:
<center><i>Being able to contribute in a meaningful way to the community</i></center>

I disagree since a member doesn't just contribute, they take away. 
Taking away from a community is a big part of what makes it a community. It doesn't matter what I contribute, if there's no one to take that contribution. 
If AI can be a member of a religious community, can we have a community of all AIs?

Furthermore, if we extrapolate this to, say, the medical community, AI already contributes to the medical community. 
Does that mean AI is already members of the medical community? Are they on the same level as a doctor or some other form of medical professional?

**What is beliefs?**
The will to believe is what differentiates a rule vs an understanding. 
Someone else said that it's the "will to choose". 

But neural network AIs are probabilistic. It has a "choice" in a way of what it extrapolates from its training data.


**Soul**
I'm very uncomfortable on having an argument based on such a abstract concept like a "soul".
It feels like a very loose foundation to base an argument on. 
What is a soul? What truly defines intent? 
We can go on defining these concepts for millennia and still not come up with the same definition.

The foundation of arguments should not be based on soft feelings in the gut but rather a solid concrete factual foundation. 
It's fine to use that gut feeling, if you can factually explain that gut feeling of a belief or a soul, but the issue is that you can't truly define it, or at least we haven't been able to yet. 

It feels like I'm building a house on top of mud, and that makes me very uncomfortable from a logical standpoint.
It's hard to create universally applicable truths without induction, since we'd often have to create a proof for every single instance.
It's better to create an objectively true insight (the base case) and a relationship between instances of that insight (the inductive case). 

But it's hard to do that if there's no solid base case in the first place.

If I can make an exact copy of myself, except using silicon rather than brain mass, a hard drive rather than memories, a neural network rather than brain neurons, does this thing / person not have a soul?

It's me, the only thing that differentiates me is the physical form in which I appear. It's the same memories, the exact same reasonings, etc. 

What differentiates me? 

Mathematics and probability is arguably the foundation of the universe

**Galileo once said, “ Mathematics is the language with which God wrote the Universe.**

In this philosophy, mathematics is how god "wrote" us, so who's to say we can't use mathematics to write our own "sentient" beings, and in a way perhaps discover new ways about ourselves?

