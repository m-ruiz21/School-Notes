The Chinese Room argument is a thought experiment by Searle that critiques the idea of "strong artificial intelligence" or GAI - the belief that a computer executing a program can have a "mind", "understanding", or "consciousness", regardless of how the computer behaves.

It's a counter to the effectiveness of the Turing experiment.

The crutch of Searle's argument is the hypothetical "Chinese Room". 

In this senario:
Image a person who doesn't understand Chinese is in a room with boxes of cards with Chinese characters and a manual that matches strings of Chinese characters with appropriate responses. 
This person receives Chinese characters through a slot, uses the manual to find an appropriate response, and sends it back through another slot.

To an outside observer, it might seem as if the room understands Chinese, but the person inside clearly doesn't understand the language - they're merely manipulating symbols.

Searle argues that, similarly, a computer program manipulating symbols doesn't understand the symbols' meanings. 
Therefore, he concludes that strong AI's claim that human thought or intelligence can be realized artificially with machines that exactly mimic the computational processes presumably underlying human mental states is false. 

Are we just making ourselves more special than we are?

Humans are different because:
- Consciousness: Searle argues that all mental states are conscious, or at least capable of being conscious.
- Intentionality: He believes that intentionality in human beings is a product of the causal features of the brain. 
	- He defined intentionality as the "aboutness" or "directedness" of mental states such as beliefs, desires, and intentions. 
	- Not all mental states are intentional, but those that are, are intrinsically about, or directed towards, something. 
- Understanding: According to Seale, true understanding requires more than just following instructions or processing information, which is what computers do. 

**Machine Learning:** AI that uses statistical analysis to shape the algorithm that determines its function. 

Can I not mold the ABOUTNESS of the model? 
- Yes, but the aboutness / intentionality is the consciousness of your purpose / aboutness. This requires a consciousness.  

Trainable vs Teachable?
Teachable - able to derive deeper symbolic meaning. Use what's been given to you to derive something new. 
Training - does specifically what it's been conditioned to do. 

Trained to regurgitate Satre vs using it to advance my own morality and beliefs. 