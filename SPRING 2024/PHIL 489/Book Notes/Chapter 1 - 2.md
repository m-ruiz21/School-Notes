# Chapter 1
**Mirror, Mirror on the wall**
****
## Notes

> Darwin and Freud dethroned our beliefs of exceptionalism, our feelings of superiority, and our fantasies of control; today, artificial intelligence seems to deal yet another blow to humanity's self image.
> **(Pg. 2, P. 2)**

This is going to be especially the case now that AI can create art, something we used to believe was very uniquely human.
How do we begin to redefine our humanity to these new parameters?

## Summary
The chapter introduces the main themes and questions of the book, which explores the ethical and social implications of artificial intelligence (AI).
The author argues that AI is not only a technical phenomenon, but also a cultural and political one, that shapes and is shaped by human values, norms, and practices. 
The chapter outlines the structure and content of the book, which consists of four parts: (1) AI and ethics, (2) AI and society, (3) AI and human nature, and (4) AI and the future. 
The chapter also explains the authorâ€™s approach and methodology, which combines philosophical analysis, empirical research, and normative reflection.
The chapter concludes by inviting the reader to engage in a critical and constructive dialogue about AI and its ethical and social challenges.

# Chapter 2
**Super intelligence, monsters, and the AI apocalypse**
****
## Summary
The chapter examines the popular and influential narratives of superintelligence, transhumanism, and the AI apocalypse, which envision a future where AI surpasses human intelligence and capabilities, and poses an existential threat to humanity. 
The author traces the origins and influences of these narratives, which often draw on religious and philosophical concepts of transcendence, singularity, and eschatology. 
The author also critiques these narratives, arguing that they are based on questionable assumptions, exaggerate the risks and benefits of AI, and distract from the more urgent and realistic ethical and social issues of AI. 
The author suggests that we need to look beyond these narratives, and explore alternative ways of imagining and relating to AI, such as those found in other cultural and historical contexts.


## Vocab
**Superintelligence:** the idea that AI will eventually surpass human intelligence (GAI) and bring about a technological singularity.

**Technological Singularity:**  the moment in human history when exponential technological progress would bring such a dramatic change that we can no longer comprehend them.

**Transhumanism**: the idea that we need to enhance the human being: make it smarter, less vulnerable to disease, live longer, and potentially even immortal - thus leading to what Harari calls *Homo deus*: humans have been upgraded to gods.

**The Frankenstein complex**: the fear of robots. 

**Transcendence**: To be "above" and independent of the physical and "moral" world.

**Immanence**: Taking a part of the physical and "moral" world.

## Notes
The chapter begins by covering: *superintelligence* and *transhumanism.* 
### Superintelligence and the Singularity

**Superintelligence** is the idea that AI will eventually surpass human intelligence (GAI) and bring about a technological singularity.
With it comes a feeling of fear, or perhaps even excitement, towards the idea that machines will take over and master *us* rather than the other way around.

Nick Bostrom sees two paths for this superintelligence:
1. AI will recursively self improve.
2. AI will be able to emulate the brain through biological brain scanning / uploading.

Both would lead to what is sometimes called an *intelligence explosion*, but for non-human intelligence.

This would lead to humanity to take the back-seat in their existence, by allowing AI to run the planet, worshiping their decisions and their judgment.
It brings about the idea that the AI will
> \[ go \] where no human has gone before - and where no human can follow.
> **(Pg. 12, P. 1)**

This idea is closely related to the idea of a *technological singularity*: a moment in human history when exponential technological progress would bring such a dramatic change that we can no longer comprehend them.
Essentially, our advancements scaling to such magnitude that it inevitably collapses on top of us, like a star caving in on itself. 

> The challenge for us today then, is to make sure that we build AI that somehow does not raise this control problem - that it does what we want and takes into consideration our rights.
> **(Pg. 14, P. 1)**

It is thus our ethical responsibility to universally define limits to AI's capabilities and create AI's contained within the structure we have defined.

**However, as power hungry as we are, are we even capable of doing that? Or will humanity join together to save itself from this reality of inevitable doom? **

### Transhumanism
While some see this as a horrible ending for humanity, some, like Ray Kurzweil, embrace the idea of the singularity. 
They argue that when, ultimately, human and machine intelligence merges, humans will transcend the limitations of their biological bodies. 

This relates to the idea of *transhumanism*. 
This is the idea that
> we need to enhance the human being: make it smarter, less vulnerable to disease, live longer, and potentially even immortal - thus leading to what Harari calls *Homo deus*: humans have been upgraded to gods.
> **Pg. 14 P.1**

The transhumanist belief is that the human machine needs an upgrade or risk becoming a 
> Slow and increasingly inefficient part of AI.
> **(Armstrong 2014, 23)**

(As detailed in the super-intelligence and singularity examples) 

However this is assuming that we will get to achieve a *General Artificial Intelligence (GAI)*, or intelligence that matches or exceeds that of humans. 
We are far from reaching this point currently, and many believe we will never reach there in the first place.

### Validity of Concerns 

The author poses the question:
Is concerning about these things (far away and extreme concepts) driving away focus from the current issues we need to tackle with AI?

> Perhaps these ideas are so influential because they touch on deep concerns and hopes regarding humans and machines that are present in our collective consciousness
> **(Pg. 16 P. 2)**

**This brings up a good point, as humans have an obsession with, inevitable doom. 
Perhaps the fear of artificial with creatures is derived from this general obsession.
To take it a step further, is it a reflection of the fear of our own mortality and our wish to be displaced from this burden through an exterior force?**

Regardless, it can be useful to target these narratives in order to contextualize some ideas, understand why the narratives exist, and help generate new narratives about the future of AI. 

### The Frankenstein Effect
There is a long history of humans and machines or artificial creatures that is worth looking into as it is prevalent in many cultures throughout the history of humanity. 

> . . . fictional stories in which machines become human-like especially fascinate us.
> **Pg. 18 P 2**

Why might this be the case?

The book talks about Frankenstein, as it is a novel influenced by the science of the author's (Mary Shelly) day. 

> \[ Frankenstein \] should not necessarily be seen as against science and technology: the main message seems to be that scientists need to take responsibility for their creations.
> The monster runs away, but it does so because the creator rejects it. 
> **Pg. 19 P 2**

The author stresses that this lesson is important to keep in mind for the ethics of AI. 
This is especially the case since this fear of technology going wild draws similarities to today's concerns about AI.

There's multiple instances of this fear not just with an artificial creation, but rather one that competes with humans. 

Like:
- *R.U.R* (1920)
- *A Space Odyssey* (2001)
- *Ex Machina* (2015)
- *The Terminator* (various movies)

This fear is referenced by Isaac Asimov as "the Frankenstein complex": the fear of robots. 

These fears, this complex, seems to be deeply rooted in our culture. 


### Transcendence and the AI Apocalypse

Interestingly:
> transhumanism and technological singularity have precedents or at least parallels in the history of Western religious culture and philosophical thinking. (sic)
> **(Pg. 22 P 1)**

Specifically, they are linked with *transcendence* and *apocalypse*.

*Transcendence*: A god is "above" and independent of the physical and "moral" world.
This is apposed to in the world and taking a part of it (immanence).

It can also refer to going beyond limits, surpassing something. 

In Judeo-Christian monotheistic tradition, God is seen as transcending his creation. 

> Frankenstein Narratives about AI seem to stress transcendence in the sense of a split or gap between creator and creation (*Homo deus* and AI), without giving much hope that this split or gap can be bridged.
> **Pg. 22 P. 2**

Plato has the idea that the body is a prison for the soul and that, while the body is mortal, the soul is immortal. 
Transhumanism gets some ideas from this:
>  Not only does it retain the goal of transcendence in the sense of overcoming human limitations, but also the specific ways this transcendence is supposed to happen evoke Plato and Gnosticism: to reach immortality, the biological body must be transcended by means of uploading and the development of artificial agents.
> **Pg. 24 P. 1**

Thus, transcendence means surpassing the human condition.  
For Christians, this may take the form of bridging the gap between God and humans by making humans into gods. 

**However, is the death of our humanity worth becoming gods?**

> Throughout humanity, people have searched for the elixir of life.
> **(Pg. 25 P.  1)**

*Apocalypse* is also a theme that is very prevalent in religion and in transhumanism. 
The main similarity relates to how:
> Most apocalyptic and eschatological ideas involve a radical and often violent disruption or destruction of the world, while heading toward a new, higher reality, being, and level of consciousness. 
> **(Pg. 25 - 26)**

### Going around the hype

To go around the hype and fear-mongering, we can look beyond Frankensteinian narratives. 

Like in Japan where technological culture is more influenced by nature religion than in the west. 
In this culture, machines are often portrayed as helpers.

Although, this way of "animistic" thinking also implies that AI can, in principle, have a spirit or soul. 
Thus, it creates the phenomena of a lack of a narrative of competition. 

**However, it's interesting to investigate why this is not the case in Western culture. What caused this Frankensteinian phenomenon?**