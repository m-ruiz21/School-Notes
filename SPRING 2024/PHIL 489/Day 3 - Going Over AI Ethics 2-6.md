# Summary / Context
Going over questions today

## Question 1
> Using AI as a human extension: does it make us less human?

**Essence vs accidents** 
We need to create a differentiation between therapeutic extensions and enhancements. 

If one is born without a leg, it is considered a therapeutic extension to replace it with a robotic leg. 
Bioethics says this is morally acceptable.
However, if one gets a bionic leg for an athletic advantage, bioethics says this is morally unacceptable.

# Question 2
> How do we classify AI? Do we consider them human, trans-human, post human? etc. 

If we follow the Kantian framework, one could argue that if machines become reliable moral agents, perhaps even greater ones than humans, then not only would it be human, it could perhaps even be *greater* than human.

However, as of now, all AI does is imitate / emulate humanity. 
There's also aspects of humanity that AI may never be able to achieve (mostly related to emotions and empathy that we innately have).

> However, this makes us think about what makes us innately humans. Will the advancement of AI also advance the understanding we have of ourselves?

There's an idea that we're "deskilling" ourselves as we gather up more tools to help us.

However, we can think of it as transitioning skills from one set of necessary skill to another.

**Agency vs patiency:** 
One who acts vs one who is acted upon
